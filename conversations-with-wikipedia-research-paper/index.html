<!DOCTYPE html>
<html data-html-server-rendered="true" lang="en" data-vue-tag="%7B%22lang%22:%7B%22ssr%22:%22en%22%7D%7D">
  <head>
    <title>Conversations with Wikipedia (Research Paper) - Arjun Kalburgi Blog</title><meta name="gridsome:hash" content="2ef915a8edff2c369f6c6610395c14cf983cab00"><meta data-vue-tag="ssr" charset="utf-8"><meta data-vue-tag="ssr" name="generator" content="Gridsome v0.7.13"><meta data-vue-tag="ssr" data-key="viewport" name="viewport" content="width=device-width, initial-scale=1, viewport-fit=cover"><meta data-vue-tag="ssr" data-key="format-detection" name="format-detection" content="telephone=no"><meta data-vue-tag="ssr" name="author" content="Arjun Kalburgi"><meta data-vue-tag="ssr" data-key="description" name="description" content="I write about my experiences and learnings. Sometimes I post my creative expressions, experiments and ideas, all in the name of sharing and expressing myself."><meta data-vue-tag="ssr" name="description" content="My research paper exploring the experience of conversational education."><meta data-vue-tag="ssr" property="og:title" content="Conversations with Wikipedia (Research Paper)"><meta data-vue-tag="ssr" property="og:image" content="https://cdn-images-1.medium.com/max/800/0*P4re_2qMolHcE0up.png"><meta data-vue-tag="ssr" property="og:type" content="article"><meta data-vue-tag="ssr" property="og:description" content="My research paper exploring the experience of conversational education."><meta data-vue-tag="ssr" property="og:updated_time" content="May 28, 2018"><meta data-vue-tag="ssr" name="twitter:description" content="My research paper exploring the experience of conversational education."><meta data-vue-tag="ssr" name="twitter:title" content="Conversations with Wikipedia (Research Paper)"><meta data-vue-tag="ssr" name="twitter:site" content="@arjunkalburgi"><meta data-vue-tag="ssr" name="twitter:image" content="https://cdn-images-1.medium.com/max/800/0*P4re_2qMolHcE0up.png"><meta data-vue-tag="ssr" name="twitter:creator" content="@arjunkalburgi"><link data-vue-tag="ssr" rel="icon" href="data:,"><link data-vue-tag="ssr" rel="icon" type="image/png" sizes="16x16" href="/writing/assets/static/Black.ce0531f.656ef5fed5ef115cc55f1754bd03deb6.png"><link data-vue-tag="ssr" rel="icon" type="image/png" sizes="32x32" href="/writing/assets/static/Black.ac8d93a.656ef5fed5ef115cc55f1754bd03deb6.png"><link data-vue-tag="ssr" rel="icon" type="image/png" sizes="96x96" href="/writing/assets/static/Black.b9532cc.656ef5fed5ef115cc55f1754bd03deb6.png"><link data-vue-tag="ssr" rel="apple-touch-icon" type="image/png" sizes="76x76" href="/writing/assets/static/Black.f22e9f3.656ef5fed5ef115cc55f1754bd03deb6.png"><link rel="preload" href="/writing/assets/css/0.styles.804e0ea9.css" as="style"><link rel="preload" href="/writing/assets/js/app.2220022f.js" as="script"><link rel="preload" href="/writing/assets/js/page--src--templates--post-vue.277ae6c2.js" as="script"><link rel="prefetch" href="/writing/assets/js/page--node-modules--gridsome--app--pages--404-vue.06b8b6f8.js"><link rel="prefetch" href="/writing/assets/js/page--src--pages--about-vue.9a904349.js"><link rel="prefetch" href="/writing/assets/js/page--src--pages--index-vue.873badb0.js"><link rel="stylesheet" href="/writing/assets/css/0.styles.804e0ea9.css"><noscript data-vue-tag="ssr"><style>.g-image--loading{display:none;}</style></noscript>
  </head>
  <body >
    <div id="app" data-server-rendered="true" data-v-476edf3e><header class="Header" data-v-0c96b5db data-v-476edf3e><a href="/" data-v-0c96b5db><img src="/writing/assets/img/LogoFull.f4addec2.svg" title="Arjun Kalburgi Leaf Logo" class="Header_logo light" data-v-0c96b5db><img src="/writing/assets/img/WhiteFull.4a906a84.svg" title="Arjun Kalburgi Leaf Logo" class="Header_logo dark" data-v-0c96b5db></a></header><div class="post section" data-v-476edf3e><div class="post_header" data-v-476edf3e><ul class="post_details" data-v-476edf3e><li data-v-476edf3e><p class="post_detail post_detail--date" data-v-476edf3e>May 28, 2018</p></li><li data-v-476edf3e><p class="post_detail post_detail--time" data-v-476edf3e>7 min read</p></li></ul><h2 class="post_title" data-v-476edf3e>Conversations with Wikipedia (Research Paper)</h2></div><div class="post_content" data-v-476edf3e><p><img src="https://cdn-images-1.medium.com/max/800/0*P4re_2qMolHcE0up.png"></p>
<p><strong>Abstract.</strong> Asking a peer to explain a concept is a simple example of learner-initiated conversation and an effective learning technique, but it is difficult to automate for many different users and topics. Research on conversational agents generally keeps to conversations of a more specific domain. In this paper, a learner-initiated conversational agent is introduced; it can converse with many users (one at a time) and is capable of discussing many topics. This poster presents this agent’s development with a specific focus on using conversational practices to help support informal learning experiences. The agent uses Wikipedia as a first step in the development of a flexible and mobile conversation-based learning experience.</p>
<blockquote>
<p>Arjun Kalburgi and Carrie Demmans Epp<br>
University of Alberta, Edmonton AB T6G 2R3, Canada<br>
{kalburgi, cdmmansepp}@ualberta.ca</p>
<p><strong>Keywords:</strong> E-learning, Conversational Agent, Wikipedia, Self-directed learning, Mobile learning, Informal learning.</p>
</blockquote>
<h4 id="1-introduction-and-motivation"><a href="#1-introduction-and-motivation" aria-hidden="true"><span class="icon icon-link"></span></a>1. Introduction and Motivation</h4>
<p>Asking a peer to explain a concept is a simple example of a learner-initiated conversation that occurs naturally. This type of learning relies on a peer to have sufficient knowledge of the topic, which is not always the case. Automating the conversation means understanding the user’s goal and the user’s requested topic, for any user and any topic. The ultimate goal of this project is to create an automated educational experience that is useful and context-dependent, just like that of conversing with a peer.</p>
<p>Existing agents create and research experiences modelled after conversing with a tutor (Nye and Graesser and Hu, 2014). These agents are designed to help users with specific knowledge areas and under specific circumstances, but utilize concepts of dialog, interaction and natural language understanding (NLU) (<a href="http://psycnet.apa.org/record/2013-31546-001" target="_blank" rel="nofollow noopener noreferrer">Katz and Albacete, 2013</a>) that are applicable to any agent.</p>
<p>The project builds a prototype e-learning agent that attempts to explore the requirements of the desired experience. The prototype is built as a command line interface (CLI) and focuses specifically on the context and dialogue of the conversational experience. Content is supplied to the agent from Wikipedia so that a large number of topics can be covered.</p>
<h4 id="2-existing-conversational-e-learning-agents"><a href="#2-existing-conversational-e-learning-agents" aria-hidden="true"><span class="icon icon-link"></span></a>2. Existing Conversational E-Learning Agents</h4>
<p>Conversational agents are still far from achieving human-like dialogue (<a href="http://aclweb.org/anthology/N/N13/N13-1098.pdf" target="_blank" rel="nofollow noopener noreferrer">Thomason and Litman</a>, 2013) despite researchers actively pursuing this goal. Dialog has been used to simulate the highly interactive nature of human tutoring (<a href="http://psycnet.apa.org/record/2013-31546-001" target="_blank" rel="nofollow noopener noreferrer">Katz and Albacete, 2013</a>), in specific domains where the conversational agent or tutoring system control most of the learning experience. However, it has been shown that there is no one size fits all language model to be used for such tutoring (<a href="https://ieeexplore.ieee.org/document/7756915/" target="_blank" rel="nofollow noopener noreferrer">Katz and Jordan and Albacete, 2016</a>). Conversational agents that help students learn by holding a conversation in natural language (Nye and Graesser and Hu, 2014) have been explored but conversations that are student-initiated have not. Existing agents ask students to explain topics, this project has the agent explaining topics from Wikipedia so the user can ask further questions.</p>
<h4 id="3-e-learning-dialog-development"><a href="#3-e-learning-dialog-development" aria-hidden="true"><span class="icon icon-link"></span></a>3. E-learning Dialog Development</h4>
<p>A conversational prototype was built from an iterative, design-based research perspective. The prototype features three parts: prompting, briefly summarizing, and conversing with the user.</p>
<h4 id="31-building-context-using-wikipedia"><a href="#31-building-context-using-wikipedia" aria-hidden="true"><span class="icon icon-link"></span></a>3.1. Building Context using Wikipedia</h4>
<p>The system needs to understand the goals of the user to have an appropriate conversation. These goals are the user’s context.</p>
<p>Wikipedia offered an approach to building this context with its large MediaWiki topology and consistently structured entries. Narrowing and filtering of information to satisfy the learner’s goals can be done by traversing the topology and scanning through the entries.</p>
<p>Both depth-first (i.e., choosing a Wikipedia page and exploring its content) and breadth-first (i.e., viewing the Wikipedia page in the topology, as it connects to other pages) explorations of the Wikipedia knowledge base were considered. To decide between these approaches, we conducted exploratory user evaluations.</p>
<p><strong>Initial Testing.</strong> The prompt, “what would you like to learn”, was used to start a discussion and observe the type of knowledge the discussion centered around. Centering around a specific topic signified depth-first interest, and centering around relations between topics signified breadth-first interest. A few college students were briefly asked the prompting question at a hackathon. The discussions displayed depth-first interest, thus the project continued using depth-first conversation.</p>
<h4 id="32-creating-the-agent-with-the-wikipedia-api"><a href="#32-creating-the-agent-with-the-wikipedia-api" aria-hidden="true"><span class="icon icon-link"></span></a>3.2. Creating the Agent with the Wikipedia API</h4>
<p>Wikipedia API libraries were used to retrieve the information and metadata from a Wikipedia page for the agent to use. A search query helped identify a Wikipedia topic for the learner and a nested list implementation of a page’s sections and subsections was useful in leading the conversation to more specific information.</p>
<p>Although conversations at this stage were possible, the text retrieved from the sections is too large and lacked conversational flow. To improve the conversation, the text needed to be summarized.</p>
<h4 id="33-creating-natural-conversation-with-the-pyteaser-api"><a href="#33-creating-natural-conversation-with-the-pyteaser-api" aria-hidden="true"><span class="icon icon-link"></span></a>3.3. Creating Natural Conversation with the PyTeaser API</h4>
<p>Interviews were conducted to better understand how the agent should create summaries and handle questions the learner may have afterwards. These 10 interviews were modelled after the existing prototype and were performed on college students.</p>
<p><strong>Extractive query focused summaries.</strong> Interviewers would summarize large text blocks using the visual and vocal feedback they received to ensure the conversation remained relevant to the interviewee. This model is called a query-focused summary.</p>
<p>The PyTeaser API was used to provide this type of summary in the prototype. The query was set to the subtopic title itself. This helped to create smaller, focused responses by the agent. However, like many other extractive summarization algorithms (<a href="http://wing.comp.nus.edu.sg/~antho/N/N10/N10-1133.pdf" target="_blank" rel="nofollow noopener noreferrer">Ceylan and Mihalcea and Ozertem and Lloret and Palomar, 2010</a>), PyTeaser’s results were often too long for them to be appropriate responses.</p>
<p><strong>Post-summary follow-up questions.</strong> During the interviews, follow-up questions were asked to help learners accomplish their learning goal.</p>
<p>This follow-up questioning was added to the agent after the summarization stage. Once the learner replies with his/her question, the agent responds by re-summarizing the topic, using keywords from the question as the query. Unfortunately the summarization again relied on PyTeaser, possibly bringing more confusion than help.</p>
<h4 id="34-improving-conversation"><a href="#34-improving-conversation" aria-hidden="true"><span class="icon icon-link"></span></a>3.4. Improving Conversation</h4>
<p><strong>Using Concepts from Summarization.</strong> The agent can use NLU techniques to find keywords and concepts to help build a summary, similar to what the interviewer would do. The agent uses the IBM Watson NLU API (Watson) to retrieve concepts from the user’s response to help provide more data to the query focused summarizer.</p>
<p><strong>Nested Subtopic Summarization.</strong> Interviewers would include subsection headers when summarizing subtopics that had their own subsections. This helped interviewers build more context as to where the conversation should go. To replicate this within the agent, an additional summarization function was made using the same technique from Watson.</p>
<p><strong>Open-Ended Questioning Upon Exit.</strong> If interviewers felt that they had failed to deliver the information the participating learner was seeking, they would simply ask if that was the case. This sparked another conversational flow for the interviewer to try to accomplish the learner’s goal.</p>
<p>As this usually happened after the learner motioned for the interview to end, the agent asks similar questions at the end of the experience.</p>
<h4 id="4-next-steps"><a href="#4-next-steps" aria-hidden="true"><span class="icon icon-link"></span></a>4. Next Steps</h4>
<p>There were many possible paths the prototype could take to further explore the potential for learner-initiated conversational agents.</p>
<p>The two APIs, PyTeaser and Watson, did not solve the original problem in most cases. Output could still be too long and lack conversational flow. Although the use of PyTeaser and Watson was serviceable for this stage of the prototype, both need to use context better to support real learning conversations.</p>
<p>Additionally, the project would benefit from being able to distinguish between conversations that meet or failed to meet the user’s learning goal. This type of metric would provide data that can be analyzed to improve the agent.</p>
<h4 id="5-conclusion"><a href="#5-conclusion" aria-hidden="true"><span class="icon icon-link"></span></a><strong>5. Conclusion</strong></h4>
<p>The prototype agent built shows the potential for learner-initiated conversations that are relevant and knowledgeable. Interviews helped establish the dialog and content of these conversations while NLU techniques helped were used to enable agent-learner conversation.</p>
<p>This exploration has the potential to be expanded on. The agent built is currently only able to discuss topics at a high level, but developing context-dependent summarization and more finely-tuned dialog would continue the exploration into deeper educational discussion.</p>
<h4 id="references"><a href="#references" aria-hidden="true"><span class="icon icon-link"></span></a><strong>References</strong></h4>
<ol>
<li>Hakan Ceylan, Rada Mihalcea, Umut Ozertem, Elena Lloret, and Manuel Palomar. 2010. Quantifying the limits and success of extractive summarization systems across domains. In <em>Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics</em>, pages 903–911, Los Angeles, California.</li>
<li>Katz, S., &#x26; Albacete, P. L. (2013). A tutoring system that simulates the highly interactive nature of human tutoring. <em>Journal of Educational Psychology</em>, pages 105(4), 1126–1141.</li>
<li>J. Thomason and D. Litman, “Differences in User Responses to a Wizard-of-Oz versus Automated System,” <em>Proc. North American Chapter Assoc. Computational Linguistics: Human Language Technologies</em> (NAACL-HLT 13), 2013, pages. 796–801.</li>
<li>S. Katz, P. Jordan &#x26; P. Albacete. Exploring How to Adaptively Apply Tutorial Dialogue Tactics. <em>In Proceedings of the 16th IEEE International Conference on Advanced Learning Technologies.</em> (ICALT2016), 2016.</li>
<li>Nye, B. D., Graesser, A. C., &#x26; Hu, X. (2014). AutoTutor and Family: A Review of 17 Years of Natural Language Tutoring. <em>International Journal of Artificial Intelligence in Education</em>, <em>24</em>(4), 427–469. <a href="http://doi.org/10.1007/s40593-014-0029-5" target="_blank" rel="nofollow noopener noreferrer">http://doi.org/10.1007/s40593-014-0029-5</a></li>
</ol>
</div></div><section id="contact" class="contact contact-style b-loaded" data-v-3ca4498e><div class="BackgroundAnimation b-lazy" data-v-c61848ac data-v-3ca4498e><div class="BackgroundAnimation_icon BackgroundAnimation_icon--1" data-v-c61848ac></div><div class="BackgroundAnimation_icon BackgroundAnimation_icon--2" data-v-c61848ac></div><div class="BackgroundAnimation_icon BackgroundAnimation_icon--3" data-v-c61848ac></div><div class="BackgroundAnimation_icon BackgroundAnimation_icon--4" data-v-c61848ac></div><div class="BackgroundAnimation_icon BackgroundAnimation_icon--5" data-v-c61848ac></div><div class="BackgroundAnimation_icon BackgroundAnimation_icon--6" data-v-c61848ac></div><div class="BackgroundAnimation_icon BackgroundAnimation_icon--7" data-v-c61848ac></div><div class="BackgroundAnimation_icon BackgroundAnimation_icon--0" data-v-c61848ac></div><div class="BackgroundAnimation_icon BackgroundAnimation_icon--1" data-v-c61848ac></div><div class="BackgroundAnimation_icon BackgroundAnimation_icon--2" data-v-c61848ac></div><div class="BackgroundAnimation_icon BackgroundAnimation_icon--3" data-v-c61848ac></div><div class="BackgroundAnimation_icon BackgroundAnimation_icon--4" data-v-c61848ac></div><div class="BackgroundAnimation_icon BackgroundAnimation_icon--5" data-v-c61848ac></div><div class="BackgroundAnimation_icon BackgroundAnimation_icon--6" data-v-c61848ac></div><div class="BackgroundAnimation_icon BackgroundAnimation_icon--7" data-v-c61848ac></div><div class="BackgroundAnimation_icon BackgroundAnimation_icon--0" data-v-c61848ac></div><div class="BackgroundAnimation_icon BackgroundAnimation_icon--1" data-v-c61848ac></div><div class="BackgroundAnimation_icon BackgroundAnimation_icon--2" data-v-c61848ac></div><div class="BackgroundAnimation_icon BackgroundAnimation_icon--3" data-v-c61848ac></div><div class="BackgroundAnimation_icon BackgroundAnimation_icon--4" data-v-c61848ac></div><div class="BackgroundAnimation_icon BackgroundAnimation_icon--5" data-v-c61848ac></div><div class="BackgroundAnimation_icon BackgroundAnimation_icon--6" data-v-c61848ac></div><div class="BackgroundAnimation_icon BackgroundAnimation_icon--7" data-v-c61848ac></div></div><div class="contact_contents" data-v-3ca4498e><h2 class="contact_contents--title" data-v-3ca4498e>More</h2><ul class="buttonlist contact_contents--links" data-v-d47a56f0 data-v-3ca4498e><!----><li class="icon" data-v-d47a56f0><a href="https://arjunkalburgi.com/writing" title="blog" class="buttonlist_icon light" data-v-d47a56f0><svg aria-hidden="true" focusable="false" data-prefix="far" data-icon="edit" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512" class="svg-inline--fa fa-edit fa-w-18" data-v-d47a56f0 data-v-d47a56f0><path fill="currentColor" d="M402.3 344.9l32-32c5-5 13.7-1.5 13.7 5.7V464c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V112c0-26.5 21.5-48 48-48h273.5c7.1 0 10.7 8.6 5.7 13.7l-32 32c-1.5 1.5-3.5 2.3-5.7 2.3H48v352h352V350.5c0-2.1.8-4.1 2.3-5.6zm156.6-201.8L296.3 405.7l-90.4 10c-26.2 2.9-48.5-19.2-45.6-45.6l10-90.4L432.9 17.1c22.9-22.9 59.9-22.9 82.7 0l43.2 43.2c22.9 22.9 22.9 60 .1 82.8zM460.1 174L402 115.9 216.2 301.8l-7.3 65.3 65.3-7.3L460.1 174zm64.8-79.7l-43.2-43.2c-4.1-4.1-10.8-4.1-14.8 0L436 82l58.1 58.1 30.9-30.9c4-4.2 4-10.8-.1-14.9z" data-v-d47a56f0 data-v-d47a56f0></path></svg></a></li><li class="icon" data-v-d47a56f0><a href="https://twitter.com/arjunkalburgi" title="twitter" class="buttonlist_icon light" data-v-d47a56f0><svg aria-hidden="true" focusable="false" data-prefix="fab" data-icon="twitter" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="svg-inline--fa fa-twitter fa-w-16" data-v-d47a56f0 data-v-d47a56f0><path fill="currentColor" d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z" data-v-d47a56f0 data-v-d47a56f0></path></svg></a></li><li class="icon" data-v-d47a56f0><a href="https://github.com/arjunkalburgi" title="github" class="buttonlist_icon light" data-v-d47a56f0><svg aria-hidden="true" focusable="false" data-prefix="fab" data-icon="github" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512" class="svg-inline--fa fa-github fa-w-16" data-v-d47a56f0 data-v-d47a56f0><path fill="currentColor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z" data-v-d47a56f0 data-v-d47a56f0></path></svg></a></li><li class="icon" data-v-d47a56f0><a href="https://linkedin.com/in/arjunkalburgi" title="linkedin" class="buttonlist_icon light" data-v-d47a56f0><svg aria-hidden="true" focusable="false" data-prefix="fab" data-icon="linkedin-in" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="svg-inline--fa fa-linkedin-in fa-w-14" data-v-d47a56f0 data-v-d47a56f0><path fill="currentColor" d="M100.28 448H7.4V148.9h92.88zM53.79 108.1C24.09 108.1 0 83.5 0 53.8a53.79 53.79 0 0 1 107.58 0c0 29.7-24.1 54.3-53.79 54.3zM447.9 448h-92.68V302.4c0-34.7-.7-79.2-48.29-79.2-48.29 0-55.69 37.7-55.69 76.7V448h-92.78V148.9h89.08v40.8h1.3c12.4-23.5 42.69-48.3 87.88-48.3 94 0 111.28 61.9 111.28 142.3V448z" data-v-d47a56f0 data-v-d47a56f0></path></svg></a></li><li class="icon" data-v-d47a56f0><a href="https://codepen.io/arjunkalburgi" title="codepen" class="buttonlist_icon light" data-v-d47a56f0><svg aria-hidden="true" focusable="false" data-prefix="fab" data-icon="codepen" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="svg-inline--fa fa-codepen fa-w-16" data-v-d47a56f0 data-v-d47a56f0><path fill="currentColor" d="M502.285 159.704l-234-156c-7.987-4.915-16.511-4.96-24.571 0l-234 156C3.714 163.703 0 170.847 0 177.989v155.999c0 7.143 3.714 14.286 9.715 18.286l234 156.022c7.987 4.915 16.511 4.96 24.571 0l234-156.022c6-3.999 9.715-11.143 9.715-18.286V177.989c-.001-7.142-3.715-14.286-9.716-18.285zM278 63.131l172.286 114.858-76.857 51.429L278 165.703V63.131zm-44 0v102.572l-95.429 63.715-76.857-51.429L234 63.131zM44 219.132l55.143 36.857L44 292.846v-73.714zm190 229.715L61.714 333.989l76.857-51.429L234 346.275v102.572zm22-140.858l-77.715-52 77.715-52 77.715 52-77.715 52zm22 140.858V346.275l95.429-63.715 76.857 51.429L278 448.847zm190-156.001l-55.143-36.857L468 219.132v73.714z" data-v-d47a56f0 data-v-d47a56f0></path></svg></a></li><li class="icon" data-v-d47a56f0><a href="mailto:askalburgi@gmail.com" title="email" class="buttonlist_icon light" data-v-d47a56f0><svg aria-hidden="true" focusable="false" data-prefix="far" data-icon="envelope" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="svg-inline--fa fa-envelope fa-w-16" data-v-d47a56f0 data-v-d47a56f0><path fill="currentColor" d="M464 64H48C21.49 64 0 85.49 0 112v288c0 26.51 21.49 48 48 48h416c26.51 0 48-21.49 48-48V112c0-26.51-21.49-48-48-48zm0 48v40.805c-22.422 18.259-58.168 46.651-134.587 106.49-16.841 13.247-50.201 45.072-73.413 44.701-23.208.375-56.579-31.459-73.413-44.701C106.18 199.465 70.425 171.067 48 152.805V112h416zM48 400V214.398c22.914 18.251 55.409 43.862 104.938 82.646 21.857 17.205 60.134 55.186 103.062 54.955 42.717.231 80.509-37.199 103.053-54.947 49.528-38.783 82.032-64.401 104.947-82.653V400H48z" data-v-d47a56f0 data-v-d47a56f0></path></svg></a></li></ul></div></section></div>
    <script>window.__INITIAL_STATE__={"data":{"post":{"id":"c2a5141c6a3d4c8968b269d7b69051a4","title":"Conversations with Wikipedia (Research Paper)","content":"\u003Cp\u003E\u003Cimg src=\"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F800\u002F0*P4re_2qMolHcE0up.png\"\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cstrong\u003EAbstract.\u003C\u002Fstrong\u003E Asking a peer to explain a concept is a simple example of learner-initiated conversation and an effective learning technique, but it is difficult to automate for many different users and topics. Research on conversational agents generally keeps to conversations of a more specific domain. In this paper, a learner-initiated conversational agent is introduced; it can converse with many users (one at a time) and is capable of discussing many topics. This poster presents this agent’s development with a specific focus on using conversational practices to help support informal learning experiences. The agent uses Wikipedia as a first step in the development of a flexible and mobile conversation-based learning experience.\u003C\u002Fp\u003E\n\u003Cblockquote\u003E\n\u003Cp\u003EArjun Kalburgi and Carrie Demmans Epp\u003Cbr\u003E\nUniversity of Alberta, Edmonton AB T6G 2R3, Canada\u003Cbr\u003E\n{kalburgi, cdmmansepp}@ualberta.ca\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cstrong\u003EKeywords:\u003C\u002Fstrong\u003E E-learning, Conversational Agent, Wikipedia, Self-directed learning, Mobile learning, Informal learning.\u003C\u002Fp\u003E\n\u003C\u002Fblockquote\u003E\n\u003Ch4 id=\"1-introduction-and-motivation\"\u003E\u003Ca href=\"#1-introduction-and-motivation\" aria-hidden=\"true\"\u003E\u003Cspan class=\"icon icon-link\"\u003E\u003C\u002Fspan\u003E\u003C\u002Fa\u003E1. Introduction and Motivation\u003C\u002Fh4\u003E\n\u003Cp\u003EAsking a peer to explain a concept is a simple example of a learner-initiated conversation that occurs naturally. This type of learning relies on a peer to have sufficient knowledge of the topic, which is not always the case. Automating the conversation means understanding the user’s goal and the user’s requested topic, for any user and any topic. The ultimate goal of this project is to create an automated educational experience that is useful and context-dependent, just like that of conversing with a peer.\u003C\u002Fp\u003E\n\u003Cp\u003EExisting agents create and research experiences modelled after conversing with a tutor (Nye and Graesser and Hu, 2014). These agents are designed to help users with specific knowledge areas and under specific circumstances, but utilize concepts of dialog, interaction and natural language understanding (NLU) (\u003Ca href=\"http:\u002F\u002Fpsycnet.apa.org\u002Frecord\u002F2013-31546-001\" target=\"_blank\" rel=\"nofollow noopener noreferrer\"\u003EKatz and Albacete, 2013\u003C\u002Fa\u003E) that are applicable to any agent.\u003C\u002Fp\u003E\n\u003Cp\u003EThe project builds a prototype e-learning agent that attempts to explore the requirements of the desired experience. The prototype is built as a command line interface (CLI) and focuses specifically on the context and dialogue of the conversational experience. Content is supplied to the agent from Wikipedia so that a large number of topics can be covered.\u003C\u002Fp\u003E\n\u003Ch4 id=\"2-existing-conversational-e-learning-agents\"\u003E\u003Ca href=\"#2-existing-conversational-e-learning-agents\" aria-hidden=\"true\"\u003E\u003Cspan class=\"icon icon-link\"\u003E\u003C\u002Fspan\u003E\u003C\u002Fa\u003E2. Existing Conversational E-Learning Agents\u003C\u002Fh4\u003E\n\u003Cp\u003EConversational agents are still far from achieving human-like dialogue (\u003Ca href=\"http:\u002F\u002Faclweb.org\u002Fanthology\u002FN\u002FN13\u002FN13-1098.pdf\" target=\"_blank\" rel=\"nofollow noopener noreferrer\"\u003EThomason and Litman\u003C\u002Fa\u003E, 2013) despite researchers actively pursuing this goal. Dialog has been used to simulate the highly interactive nature of human tutoring (\u003Ca href=\"http:\u002F\u002Fpsycnet.apa.org\u002Frecord\u002F2013-31546-001\" target=\"_blank\" rel=\"nofollow noopener noreferrer\"\u003EKatz and Albacete, 2013\u003C\u002Fa\u003E), in specific domains where the conversational agent or tutoring system control most of the learning experience. However, it has been shown that there is no one size fits all language model to be used for such tutoring (\u003Ca href=\"https:\u002F\u002Fieeexplore.ieee.org\u002Fdocument\u002F7756915\u002F\" target=\"_blank\" rel=\"nofollow noopener noreferrer\"\u003EKatz and Jordan and Albacete, 2016\u003C\u002Fa\u003E). Conversational agents that help students learn by holding a conversation in natural language (Nye and Graesser and Hu, 2014) have been explored but conversations that are student-initiated have not. Existing agents ask students to explain topics, this project has the agent explaining topics from Wikipedia so the user can ask further questions.\u003C\u002Fp\u003E\n\u003Ch4 id=\"3-e-learning-dialog-development\"\u003E\u003Ca href=\"#3-e-learning-dialog-development\" aria-hidden=\"true\"\u003E\u003Cspan class=\"icon icon-link\"\u003E\u003C\u002Fspan\u003E\u003C\u002Fa\u003E3. E-learning Dialog Development\u003C\u002Fh4\u003E\n\u003Cp\u003EA conversational prototype was built from an iterative, design-based research perspective. The prototype features three parts: prompting, briefly summarizing, and conversing with the user.\u003C\u002Fp\u003E\n\u003Ch4 id=\"31-building-context-using-wikipedia\"\u003E\u003Ca href=\"#31-building-context-using-wikipedia\" aria-hidden=\"true\"\u003E\u003Cspan class=\"icon icon-link\"\u003E\u003C\u002Fspan\u003E\u003C\u002Fa\u003E3.1. Building Context using Wikipedia\u003C\u002Fh4\u003E\n\u003Cp\u003EThe system needs to understand the goals of the user to have an appropriate conversation. These goals are the user’s context.\u003C\u002Fp\u003E\n\u003Cp\u003EWikipedia offered an approach to building this context with its large MediaWiki topology and consistently structured entries. Narrowing and filtering of information to satisfy the learner’s goals can be done by traversing the topology and scanning through the entries.\u003C\u002Fp\u003E\n\u003Cp\u003EBoth depth-first (i.e., choosing a Wikipedia page and exploring its content) and breadth-first (i.e., viewing the Wikipedia page in the topology, as it connects to other pages) explorations of the Wikipedia knowledge base were considered. To decide between these approaches, we conducted exploratory user evaluations.\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cstrong\u003EInitial Testing.\u003C\u002Fstrong\u003E The prompt, “what would you like to learn”, was used to start a discussion and observe the type of knowledge the discussion centered around. Centering around a specific topic signified depth-first interest, and centering around relations between topics signified breadth-first interest. A few college students were briefly asked the prompting question at a hackathon. The discussions displayed depth-first interest, thus the project continued using depth-first conversation.\u003C\u002Fp\u003E\n\u003Ch4 id=\"32-creating-the-agent-with-the-wikipedia-api\"\u003E\u003Ca href=\"#32-creating-the-agent-with-the-wikipedia-api\" aria-hidden=\"true\"\u003E\u003Cspan class=\"icon icon-link\"\u003E\u003C\u002Fspan\u003E\u003C\u002Fa\u003E3.2. Creating the Agent with the Wikipedia API\u003C\u002Fh4\u003E\n\u003Cp\u003EWikipedia API libraries were used to retrieve the information and metadata from a Wikipedia page for the agent to use. A search query helped identify a Wikipedia topic for the learner and a nested list implementation of a page’s sections and subsections was useful in leading the conversation to more specific information.\u003C\u002Fp\u003E\n\u003Cp\u003EAlthough conversations at this stage were possible, the text retrieved from the sections is too large and lacked conversational flow. To improve the conversation, the text needed to be summarized.\u003C\u002Fp\u003E\n\u003Ch4 id=\"33-creating-natural-conversation-with-the-pyteaser-api\"\u003E\u003Ca href=\"#33-creating-natural-conversation-with-the-pyteaser-api\" aria-hidden=\"true\"\u003E\u003Cspan class=\"icon icon-link\"\u003E\u003C\u002Fspan\u003E\u003C\u002Fa\u003E3.3. Creating Natural Conversation with the PyTeaser API\u003C\u002Fh4\u003E\n\u003Cp\u003EInterviews were conducted to better understand how the agent should create summaries and handle questions the learner may have afterwards. These 10 interviews were modelled after the existing prototype and were performed on college students.\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cstrong\u003EExtractive query focused summaries.\u003C\u002Fstrong\u003E Interviewers would summarize large text blocks using the visual and vocal feedback they received to ensure the conversation remained relevant to the interviewee. This model is called a query-focused summary.\u003C\u002Fp\u003E\n\u003Cp\u003EThe PyTeaser API was used to provide this type of summary in the prototype. The query was set to the subtopic title itself. This helped to create smaller, focused responses by the agent. However, like many other extractive summarization algorithms (\u003Ca href=\"http:\u002F\u002Fwing.comp.nus.edu.sg\u002F~antho\u002FN\u002FN10\u002FN10-1133.pdf\" target=\"_blank\" rel=\"nofollow noopener noreferrer\"\u003ECeylan and Mihalcea and Ozertem and Lloret and Palomar, 2010\u003C\u002Fa\u003E), PyTeaser’s results were often too long for them to be appropriate responses.\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cstrong\u003EPost-summary follow-up questions.\u003C\u002Fstrong\u003E During the interviews, follow-up questions were asked to help learners accomplish their learning goal.\u003C\u002Fp\u003E\n\u003Cp\u003EThis follow-up questioning was added to the agent after the summarization stage. Once the learner replies with his\u002Fher question, the agent responds by re-summarizing the topic, using keywords from the question as the query. Unfortunately the summarization again relied on PyTeaser, possibly bringing more confusion than help.\u003C\u002Fp\u003E\n\u003Ch4 id=\"34-improving-conversation\"\u003E\u003Ca href=\"#34-improving-conversation\" aria-hidden=\"true\"\u003E\u003Cspan class=\"icon icon-link\"\u003E\u003C\u002Fspan\u003E\u003C\u002Fa\u003E3.4. Improving Conversation\u003C\u002Fh4\u003E\n\u003Cp\u003E\u003Cstrong\u003EUsing Concepts from Summarization.\u003C\u002Fstrong\u003E The agent can use NLU techniques to find keywords and concepts to help build a summary, similar to what the interviewer would do. The agent uses the IBM Watson NLU API (Watson) to retrieve concepts from the user’s response to help provide more data to the query focused summarizer.\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cstrong\u003ENested Subtopic Summarization.\u003C\u002Fstrong\u003E Interviewers would include subsection headers when summarizing subtopics that had their own subsections. This helped interviewers build more context as to where the conversation should go. To replicate this within the agent, an additional summarization function was made using the same technique from Watson.\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cstrong\u003EOpen-Ended Questioning Upon Exit.\u003C\u002Fstrong\u003E If interviewers felt that they had failed to deliver the information the participating learner was seeking, they would simply ask if that was the case. This sparked another conversational flow for the interviewer to try to accomplish the learner’s goal.\u003C\u002Fp\u003E\n\u003Cp\u003EAs this usually happened after the learner motioned for the interview to end, the agent asks similar questions at the end of the experience.\u003C\u002Fp\u003E\n\u003Ch4 id=\"4-next-steps\"\u003E\u003Ca href=\"#4-next-steps\" aria-hidden=\"true\"\u003E\u003Cspan class=\"icon icon-link\"\u003E\u003C\u002Fspan\u003E\u003C\u002Fa\u003E4. Next Steps\u003C\u002Fh4\u003E\n\u003Cp\u003EThere were many possible paths the prototype could take to further explore the potential for learner-initiated conversational agents.\u003C\u002Fp\u003E\n\u003Cp\u003EThe two APIs, PyTeaser and Watson, did not solve the original problem in most cases. Output could still be too long and lack conversational flow. Although the use of PyTeaser and Watson was serviceable for this stage of the prototype, both need to use context better to support real learning conversations.\u003C\u002Fp\u003E\n\u003Cp\u003EAdditionally, the project would benefit from being able to distinguish between conversations that meet or failed to meet the user’s learning goal. This type of metric would provide data that can be analyzed to improve the agent.\u003C\u002Fp\u003E\n\u003Ch4 id=\"5-conclusion\"\u003E\u003Ca href=\"#5-conclusion\" aria-hidden=\"true\"\u003E\u003Cspan class=\"icon icon-link\"\u003E\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003Cstrong\u003E5. Conclusion\u003C\u002Fstrong\u003E\u003C\u002Fh4\u003E\n\u003Cp\u003EThe prototype agent built shows the potential for learner-initiated conversations that are relevant and knowledgeable. Interviews helped establish the dialog and content of these conversations while NLU techniques helped were used to enable agent-learner conversation.\u003C\u002Fp\u003E\n\u003Cp\u003EThis exploration has the potential to be expanded on. The agent built is currently only able to discuss topics at a high level, but developing context-dependent summarization and more finely-tuned dialog would continue the exploration into deeper educational discussion.\u003C\u002Fp\u003E\n\u003Ch4 id=\"references\"\u003E\u003Ca href=\"#references\" aria-hidden=\"true\"\u003E\u003Cspan class=\"icon icon-link\"\u003E\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003Cstrong\u003EReferences\u003C\u002Fstrong\u003E\u003C\u002Fh4\u003E\n\u003Col\u003E\n\u003Cli\u003EHakan Ceylan, Rada Mihalcea, Umut Ozertem, Elena Lloret, and Manuel Palomar. 2010. Quantifying the limits and success of extractive summarization systems across domains. In \u003Cem\u003EHuman Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics\u003C\u002Fem\u003E, pages 903–911, Los Angeles, California.\u003C\u002Fli\u003E\n\u003Cli\u003EKatz, S., &#x26; Albacete, P. L. (2013). A tutoring system that simulates the highly interactive nature of human tutoring. \u003Cem\u003EJournal of Educational Psychology\u003C\u002Fem\u003E, pages 105(4), 1126–1141.\u003C\u002Fli\u003E\n\u003Cli\u003EJ. Thomason and D. Litman, “Differences in User Responses to a Wizard-of-Oz versus Automated System,” \u003Cem\u003EProc. North American Chapter Assoc. Computational Linguistics: Human Language Technologies\u003C\u002Fem\u003E (NAACL-HLT 13), 2013, pages. 796–801.\u003C\u002Fli\u003E\n\u003Cli\u003ES. Katz, P. Jordan &#x26; P. Albacete. Exploring How to Adaptively Apply Tutorial Dialogue Tactics. \u003Cem\u003EIn Proceedings of the 16th IEEE International Conference on Advanced Learning Technologies.\u003C\u002Fem\u003E (ICALT2016), 2016.\u003C\u002Fli\u003E\n\u003Cli\u003ENye, B. D., Graesser, A. C., &#x26; Hu, X. (2014). AutoTutor and Family: A Review of 17 Years of Natural Language Tutoring. \u003Cem\u003EInternational Journal of Artificial Intelligence in Education\u003C\u002Fem\u003E, \u003Cem\u003E24\u003C\u002Fem\u003E(4), 427–469. \u003Ca href=\"http:\u002F\u002Fdoi.org\u002F10.1007\u002Fs40593-014-0029-5\" target=\"_blank\" rel=\"nofollow noopener noreferrer\"\u003Ehttp:\u002F\u002Fdoi.org\u002F10.1007\u002Fs40593-014-0029-5\u003C\u002Fa\u003E\u003C\u002Fli\u003E\n\u003C\u002Fol\u003E\n","date":"May 28, 2018","timeToRead":7,"description":"My research paper exploring the experience of conversational education.","cover":"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F800\u002F0*P4re_2qMolHcE0up.png"}},"context":{}};(function(){var s;(s=document.currentScript||document.scripts[document.scripts.length-1]).parentNode.removeChild(s);}());</script><script src="/writing/assets/js/app.2220022f.js" defer></script><script src="/writing/assets/js/page--src--templates--post-vue.277ae6c2.js" defer></script>
  </body>
</html>
